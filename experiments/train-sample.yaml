seml:
  project_root_dir: ..
  executable: experiments/train-tmp.py
  name: train
  output_dir: /nfs/students/ayle/NodeDP/logs
  conda_environment: gcn-dp

slurm:
  experiments_per_job: 1
  sbatch_options:
    gres: gpu:1       # num GPUs
    mem: 16G          # memory
    cpus-per-task: 1  # num cores
    time: 1-00:00     # max time, D-HH:MM
    partition: ['gpu_all']
#    qos: interactive

###### BEGIN PARAMETER CONFIGURATION ######

fixed:
  data_path: './data/ogbn-arxiv_undirected'
#  data_path: './data/ppi'
  use_cuda: True
  eval_every: 1
  num_iterations: 1000
#  seed: 1234

  sampler_args:
    method: 'pre_drw_w_restarts'  # options: {rw, drw, pre_drw, pre_drw_w_restarts, baseline}
    num_root: 5000
    depth: 2
#    max_degree: 2
    restarts: 2

  model_args:
    arch: 'GCN'
    hidden_channels: 512
    dropout: 0.0
    num_layers: 2
    activation: 'relu'

  training_args:
    accountant: 'dp'  # options: {none, baseline, std, sub_rdp}
    loss: 'softmax'
#    lr: 0.05
    optim: 'Adam'
    early_stopping_after: 20
#    clip_norm: 5

#    C%: 1000000
#    alpha: 2
#    delta: 1e-6
#    max_eps: 15
#    sigma: None

grid:

  seed:
    type: choice
    options:
      - 1234
      - 2345
#      - 3456

  training_args.lr:
    type: choice
    options:
#      - 0.005
      - 0.01
#      - 0.03
#      - 0.04
#      - 0.05
#      - 0.06
#      - 0.07
#      - 0.08
#      - 0.09
      - 0.1
#      - 0.12
#      - 0.14

  training_args.C%:
    type: choice
    options:
      - 0.05
#      - 0.25
      - 0.5
      - 1
      - 1e1
      - 1e2
#      - 1e3
#      - 1e6
